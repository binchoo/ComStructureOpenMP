# 다익스트라 알고리즘 병렬화 보고

## 직렬 다익스트라 알고리즘
### 변수 명세

- `cost` : 각 지점을 잇는 선분의 가중치를 표현하는 2차원 `size*size` 정방행렬
- `dist` : `source` 지점에서 부터 각 지점까지 거리를 갱신하는 `size` 길이의 배열.
- `graphed` : `i` 번째 지점이 그래프에 포함되는지 나타낸다. `!graphed[i]` 이면 `i`는 아직 그래프에 없다.
- `updater_of` : `updater_of[i]`는 `i`번째 지점의 `dist`를 갱신한 최근 노드를 기록한다.
- `path_true` : 최단거리를 구한 뒤 최단경로를 출력하는 옵션

## 직렬 알고리즘의 병렬화 후보군
다익스트라 알고리즘에서 OpenMP로 병렬화 할 수 있는 부분을 찾으려 한다. 알고리즘의 흐름은 4단계로 요약할 수 있다. 첫 째, `dist` 배열을 `INT_MAX`로 초기화하는 단계이다. 여기서 여러 스레드가 초기화 할 부분을 나눠 작업하는 것은 유용하리라 생각된다.
```c++
int dijkstra(int** cost, int size, int source, int target)
{
	int dist[size];
	int graphed[size] = { 0 };
	int updater_of[size];
	register int i, start, d;

	for(i = 0; i < size; i++) {
		dist[i] = INT_MAX;
	} dist[source] = 0, updater_of[source] = -1;
	while(!graphed[target]) {
		start = arg_min(dist, graphed, size);
		graphed[start] = 1;
```

두 번째 단계는 그래프 밖에 있는 노드중에 가장 작은 `dist` 를 갖는 노드를 찾아 그래프로 편입시키는 것이다. 해당 노드를 찾는 일은 `arg_min` 함수를 통해 실현되며 함수의 내용은 아래 코드에 나와있다. `graphed` 와 `dist` 배열을 탐색하면서 `min`과 `arg_min` 이 갱신되고 있는데, 이 작업은 여러 스레드로 분담할 수 있다. 스레드가 각자의 영역에서 `local_min`과 `local_arg_min`을 갱신하고, 마지막에 이들 중에서 가장 작은 `global_min` 을 찾으면 될 것이다.

```c++
int arg_min(int* dist, int* graphed, int size)
{
	register int i, arg_min, min = INT_MAX;
	for(i = 0; i < size; i++) {
		if(!graphed[i] && dist[i] < min) {
			min = dist[i];
			arg_min = i;
		}
	} return arg_min;
}
```



세 번째 단계는, 방금 그래프에 편입된 노드의 이웃 노드에게 새로운 거리를 부여하는 것이다. 거리가 갱신되면 자신을 갱신시킨 `start` 노드를 `updater_of`에 기록한다. 3 단계도 마찬가지로, 스레드 간 담당하는 노드를 나누어 처리하는 것이 가능하다.

```c++
	while(!graphed[target]) {
		start = arg_min(dist, graphed, size);
		graphed[start] = 1;
		for (i = 0; i < size; i++) {
			if(cost[start][i] && !graphed[i]) {
				d = dist[start] + cost[start][i];
				if (d < dist[i]) {
					dist[i] = d;
					updater_of[i] = start;
				}
			}
		}
	}
```



네 번째 단계는, `path_true` 옵션이 참 일 경우 최단경로를 화면에 출력하는 것이다. 경로를 알아내기 위해 `updator_of[target]`을 거꾸로 따라올라간다. 그러므로 한 시점의 값이 이전 시점의 값과 커플링되어있어 `updator_of`에 병렬로 접근하는 것은 불가능하다. 

```c++
	if(path_true) {
		int buffer[size];
		register int buf_len = 0;
		start = target;
		do {
			buffer[buf_len++] = start;
		} while ((start = updater_of[start]) != -1);

		_print_student_id();
		for(i = buf_len - 1; i >= 0; i--) {
			printf("n%04d ", buffer[i]);
		} printf("\n");
	} return dist[target];
```



## 자료 증가율에 따른 병렬화 성능 테스트

병렬화 후보를 실제 omp코드로 작성하기에 앞서, 멀티 스레드를 사용한 간단한 연산을 수 차례 테스트 해보았다. 과연 얼마나 큰 자료가 입력되어야 속도측면의 이득을 기대할 수 있는지 확인하는 것이 목적이었다. 테스트 환경은 `4스레드 i7-4790k 8GB RAM` 이며 wall clock time을 측정하였다.

### 배열 초기화 연산

천, 만, 십 만, INT_MAX/10 길이를 갖는 배열에 대한 초기화를 `prgma omp for`로 수행해 보았다. 직렬 알고리즘과 수행시간을 비교하니 다음 표와 같았다. 매우 큰 크기의 배열을 초기화 할 때는 병렬 프로그램이 빠른 것을 체감할 수 있었다. 그러나 다익스트라 알고리즘에 투입될 노드의 갯수가 100만 개 가량이 되지 않는다면 배열을 초기화하는 단계는 `omp`로 구현하지 않아도 될 것이다. 그러므로 다익스트라의 1 단계는 병렬화 하지 않기로 했다.

| 데이터의 수           | parallel        | serial          |
| --------------------- | --------------- | --------------- |
| 천 개                 | 0.000195 ms     | **0.000000 ms** |
| 만 개                 | 0.000227 ms     | **0.000074 ms** |
| 십만 개               | **0.000423 ms** | 0.000432 ms     |
| INT_MAX / 10 개 ~ 2억 | **0.211551 ms** | 0.321746 ms     |

### MIN 연산

10^2, 100^2, 1000^2, 10000^2 행렬에 대해 min 연산을 병렬 처리해 보았다. min 연산은 heap~O(logn) 방식이 아닌, 가장 간단한 O(n) 방식을 변형한 것이며 앞서 말한 `local_min`을 사용하는 방법이다. min 연산은 for문 안에서 앞선 배정연산 테스트보다 더 많은 메모리 접근과 산술연산이 사용되며, 다익스트라에서 최악의 경우 `size`만큼 반복된다. 테스트 시간을 측정한 결과는 아래의 표와 같다.

| 데이터의 수 | parallel        | serial          |
| ----------- | --------------- | --------------- |
| 백 개       | 0.00268 ms      | **0.000003 ms** |
| 만 개       | 0.00237 ms      | **0.000043 ms** |
| 백만 개     | **0.000497 ms** | 0.000794 ms     |
| 일억 개     | **0.039039 ms** | 0.085311 ms     |

투입될 노드의 개수가 만 개라면 병렬화를 해도 좋을 지 와닿지 않는다. 그러나 병렬 알고리즘이 보여주는 속도향상률은 충분히 활용할 만 하다. 그러므로 다익스트라의 2, 3 단계는 노드 개수에 따라 선택적으로 병렬 알고리즘을 호출하는 방법을 적용하겠다.

## MINIMUM 힙 적용 사례

min 연산을 O(logn)으로 바꾸기 위해 minimun 힙 자료구조를 사용해 보았다. 그러나 준비되어있는 1만 노드 데이터로 테스트 하였을 때 힙 알고리즘이 배열 기반 알고리즘을 이기는 일은 없었으므로 알고리즘에 적용하지 않았다. 힙 구조의 덕을 보려면 더 큰 데이터가 준비되어야 할 것 같다.

## 최종 알고리즘

#### dijkstra

- 반복문에서 사용되는 int 자료들은 되도록이면 레지스터를 이용하기 위해 `register` 키워드로  명시하였다.
- 배열을 초기화하는 부분은 `omp`를 사용하지 않는다.
- 최소거리 노드를 찾고 거리를 갱신하는 부분은, 노드의 수가  `DO_PARALLEL` 크기를 넘을 때만 병렬로 수행한다. 이러한 선택 방식이 존재할 때와 존재하지 않을 때의 속도 비교는 뒷 장에 있다. 병렬로 최소거리 노드를 찾을 때 사용되는 함수는  `arg_min_parallel`이고 `omp`로 작성된 코드이다. 
- 스레드 유휴시간을 줄일 목적으로 로드 밸런싱을 적용하였다. `chunk_size`=13은 실험적으로 결정했으며, 캐시 overwrite를 피하기 위해 상대적으로 작은 블록 중에서 하나를 선택하였다.

```c++
...
for(i = 0; i < size; i++) {
		dist[i] = INT_MAX;
	}dist[source] = 0, updater_of[source] = -1;
	while(!graphed[target]) {
		if(size > DO_PARALLEL) {
			start = arg_min_parallel(dist, graphed, size);
			graphed[start] = 1;

			#pragma omp parallel for schedule(static, 13)
			for (i = 0; i < size; i++) {
				if(cost[start][i] && !graphed[i]) {
					d = dist[start] + cost[start][i];
					if (d < dist[i]) {
						dist[i] = d;
						updater_of[i] = start;
					}
				}
			}
		} else {
			start = arg_min(dist, graphed, size);
			graphed[start] = 1;

			for (i = 0; i < size; i++) {
				if(cost[start][i] && !graphed[i]) {
					d = dist[start] + cost[start][i];
					if (d < dist[i]) {
						dist[i] = d;
						updater_of[i] = start;
					}
				}
			}
		}
	}
...
```

#### arg_min_parallel

- 매 호출마다 `local_arg_min`을 생성해야 할 필요가 없다. 따라서 `static` 으로 선언하였다.
- 스레드는 각자 `local_min` 과 해당 값을 갖는 노드의 번호인  `local_arg_min`를 구한다.
- 마직막에 가장 큰 `glob_min`과 해당 값을 갖는 노드의 번호인 `arg_min`을 구하여 반환한다.

```c++
int arg_min_parallel(int* dist, int* graphed, int size)
{
	static int* local_arg_min = (int*)malloc(sizeof(int) * n_thread);
	register int i;
	#pragma omp parallel
	{
		register int my_id = omp_get_thread_num();
		register int local_min = INT_MAX;
		local_arg_min[my_id] = -1;
		#pragma omp for schedule(static, 13)
		for(i = 0; i < size; i++) {
			if(!graphed[i] && dist[i] < local_min) {
				local_min = dist[i];
				local_arg_min[my_id] = i;
			}
		}
	}
	register int glob_min = INT_MAX;
	register int arg_min = 0;
	register int my_arg;
	for(i = 0; i < n_thread; i++) {
		my_arg = local_arg_min[i];
		if(my_arg != -1 && dist[my_arg] < glob_min) {
			glob_min = dist[my_arg];
			arg_min = my_arg;
		}
	} return arg_min;
}
```

#### 노드 수에 의한 선택 전략과 시간 비교

제안한 알고리즘은 사전에 정의한 값인 `DO_PARALLEL` 보다 그래프 노드가 많을 경우에 병렬화 된 코드를 수행한다. 아래의 표는`DO_PARALLEL`  값을 세 가지로 변화시면서, 세 가지 그래프에서, 세 가지 경로를 구하는 시간을 측정한 것이다. `mapDist10000.csv` 와 `mapDist15000.csv`은 `Python Numpy`로 임의로 생성한 정방행렬이다. 

| `DO_PARALLEL` = 0 | mapDist1600 (병렬) | mapDist10000(병렬) | mapDist15000(병렬) |
| ----------------- | ------------------ | ------------------ | ------------------ |
| 경로 : 300 →1000  | 0.010              | 0.054              | 0.015              |
| 경로 : 200 →1300         | 0.005              | 0.048              | 0.016              |
| 경로 : 100 →200          | 0.010              | 0.075              | 0.060              |

| `DO_PARALLEL` = 9999 | mapDist1600 (직렬) | mapDist10000 (병렬) | mapDist15000 (병렬) |
| -------------------- | ------------------ | ------------------- | ------------------- |
| 경로 : 300 →1000            | 0.005              | 0.054               | 0.017               |
| 경로 : 200 →1300            | 0.002              | 0.057               | 0.017               |
| 경로 : 100 →200             | 0.006              | 0.076               | 0.053               |

| `DO_PARALLEL` = INT_MAX | mapDist1600 (직렬) | mapDist10000 (직렬) | mapDist15000 (직렬) |
| ----------------------- | ------------------ | ------------------- | ------------------- |
| 경로 : 300 →1000               | 0.005              | 0.096               | 0.069               |
| 경로 : 200 →1300               | 0.002              | 0.097               | 0.084               |
| 경로 : 100 →200                | 0.006              | 0.057               | 0.043               |

결과로 비추어 보아 그래프 노드가 적을 때에 직렬 다익스트라를 사용하고, 노드가 많을 때에 병렬 다익스트라를 사용하는 전략이 유효한 것으로 보인다. 단, 그래프의 형태에 따라 수행속도 역시 다양할 것이므로 단 3가지 경로만으로는 테스트를 진행한 것은 부족한 정보가 될 수 있다

